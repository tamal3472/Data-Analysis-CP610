{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a39bba82",
   "metadata": {},
   "source": [
    "## <center> Assignment 2 </center>\n",
    "\n",
    "#### Name:\n",
    "#### Student ID:\n",
    "\n",
    "You are provided with a training dataset and a testing dataset for a binary classification problem with labels {0,1}. The last column of the training set is the label, while the test dataset contains only attributes.\n",
    "\n",
    "Train an effective classifier using the training dataset. You are free to choose your data processing approach, the classifier type, and tune the classifier's parameters as needed. You can use the sklearn package in Python for model implementation. \n",
    "\n",
    "Make predictions on the testing dataset and generate a file containing only one column of labels (predicted 0 or 1), in the same order as the testing dataset.\n",
    "\n",
    "Please submit your implementation code and the predicted output file as two separate files (not in a zip) in the names \"A2.ipynb\" and \"prediction.txt\". Your assignment will be eTestinguated based on the performance of your model, specifically its F1-score, among other criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "71b2a48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all essential libraries\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, matthews_corrcoef, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "88afc5f1-7080-4275-84b2-1dea10a80b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "train_data = pd.read_csv(\"train_attribute.csv\")\n",
    "test_data = pd.read_csv(\"test_attribute.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "a4ca11ee-aa7d-485e-8cb3-ef4855b1dc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and labels\n",
    "x = train_data.iloc[:, :-1]\n",
    "y = train_data.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "15753440-ffdd-4d70-bae6-35e8a1af474a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Unnamed: 0     0     1     2     3    4    5     6     7\n",
      "0             0  0.81  0.85  0.47  0.37  0.5  0.0  0.56  0.22\n",
      "1             1  0.70  0.58  0.53  0.39  0.5  0.0  0.59  0.22\n",
      "2             2  0.72  0.73  0.41  0.28  0.5  0.0  0.44  0.22\n",
      "3             3  0.78  0.69  0.44  0.26  0.5  0.0  0.54  0.22\n",
      "4             4  0.74  0.82  0.46  0.24  0.5  0.0  0.48  0.22\n",
      "..          ...   ...   ...   ...   ...  ...  ...   ...   ...\n",
      "647         647  0.48  0.47  0.54  0.55  0.5  0.0  0.51  0.65\n",
      "648         648  0.49  0.61  0.49  0.25  0.5  0.0  0.50  0.28\n",
      "649         649  0.48  0.43  0.45  0.17  0.5  0.0  0.48  0.37\n",
      "650         650  0.77  0.57  0.45  0.17  0.5  0.0  0.53  0.22\n",
      "651         651  0.49  0.48  0.46  0.63  0.5  0.0  0.52  0.22\n",
      "\n",
      "[652 rows x 9 columns]\n",
      "0      1\n",
      "1      1\n",
      "2      1\n",
      "3      1\n",
      "4      1\n",
      "      ..\n",
      "647    0\n",
      "648    0\n",
      "649    0\n",
      "650    0\n",
      "651    0\n",
      "Name: 8, Length: 652, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "d7cb5f6f-0551-43a3-904d-f8d082aeb52e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(456, 9) (456,)\n",
      "(196, 9) (196,)\n"
     ]
    }
   ],
   "source": [
    "# Split training data for testing\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.30, random_state=1234)\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "8f3c462e-1298-4091-be64-55d2d9c3b438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model performance for Training Set Using Random Forest\n",
      "- Accuracy: 1.0\n",
      "- MCC: 1.0\n",
      "- F1 score: 1.0\n",
      "----------------------------------\n",
      "Model performance for Testing set Using Random Forest\n",
      "- Accuracy: 0.9948979591836735\n",
      "- MCC: 0.9674439066004296\n",
      "- F1 score: 0.9948277614413706\n"
     ]
    }
   ],
   "source": [
    "# RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(random_state=0)\n",
    "rf.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions on the training and training sets\n",
    "y_train_pred = rf.predict(x_train)\n",
    "y_test_pred = rf.predict(x_test)\n",
    "\n",
    "# Training set performance\n",
    "rf_train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "rf_train_mcc = matthews_corrcoef(y_train, y_train_pred)\n",
    "rf_train_f1 = f1_score(y_train, y_train_pred, average='weighted')\n",
    "\n",
    "# Test set performance\n",
    "rf_test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "rf_test_mcc = matthews_corrcoef(y_test, y_test_pred)\n",
    "rf_test_f1 = f1_score(y_test, y_test_pred, average='weighted')\n",
    "\n",
    "print('Model performance for Training Set Using Random Forest')\n",
    "print('- Accuracy: %s' % rf_train_accuracy)\n",
    "print('- MCC: %s' % rf_train_mcc)\n",
    "print('- F1 score: %s' % rf_train_f1)\n",
    "print('----------------------------------')\n",
    "print('Model performance for Testing set Using Random Forest')\n",
    "print('- Accuracy: %s' % rf_test_accuracy)\n",
    "print('- MCC: %s' % rf_test_mcc)\n",
    "print('- F1 score: %s' % rf_test_f1)\n",
    "\n",
    "# Make predictions on the test dataset\n",
    "y_test_pred = rf.predict(x_test)\n",
    "\n",
    "# Save predictions to \"prediction.txt\"\n",
    "pd.DataFrame(y_test_pred, columns=[\"Predicted\"]).to_csv(\"prediction_RF.txt\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "adfde62f-7687-4da9-b222-16f1d2b8c32a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model performance for Training set using KNN\n",
      "- Accuracy: 0.9978070175438597\n",
      "- MCC: 0.9880972998652703\n",
      "- F1 score: 0.9977965661327292\n",
      "----------------------------------\n",
      "Model performance for Testing set using KNN\n",
      "- Accuracy: 0.9948979591836735\n",
      "- MCC: 0.9674439066004296\n",
      "- F1 score: 0.9948277614413706\n"
     ]
    }
   ],
   "source": [
    "# KNeighborsClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions on the training and testing sets\n",
    "y_train_pred = knn.predict(x_train)\n",
    "y_test_pred = knn.predict(x_test)\n",
    "\n",
    "# Training set performance\n",
    "knn_train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "knn_train_mcc = matthews_corrcoef(y_train, y_train_pred)\n",
    "knn_train_f1 = f1_score(y_train, y_train_pred, average='weighted')\n",
    "\n",
    "# Testing set performance\n",
    "knn_test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "knn_test_mcc = matthews_corrcoef(y_test, y_test_pred)\n",
    "knn_test_f1 = f1_score(y_test, y_test_pred, average='weighted')\n",
    "\n",
    "print('Model performance for Training set using KNN')\n",
    "print('- Accuracy: %s' % knn_train_accuracy)\n",
    "print('- MCC: %s' % knn_train_mcc)\n",
    "print('- F1 score: %s' % knn_train_f1)\n",
    "print('----------------------------------')\n",
    "print('Model performance for Testing set using KNN')\n",
    "print('- Accuracy: %s' % knn_test_accuracy)\n",
    "print('- MCC: %s' % knn_test_mcc)\n",
    "print('- F1 score: %s' % knn_test_f1)\n",
    "\n",
    "# Make predictions on the test dataset\n",
    "y_test_pred = knn.predict(x_test)\n",
    "\n",
    "# Save predictions to \"prediction.txt\"\n",
    "pd.DataFrame(y_test_pred, columns=[\"Predicted\"]).to_csv(\"prediction_KNN.txt\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "72114e5a-f66a-4ae1-bfdb-4eaf6c1314fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model performance for Training set\n",
      "- Accuracy: 1.0\n",
      "- MCC: 1.0\n",
      "- F1 score: 1.0\n",
      "----------------------------------\n",
      "Model performance for Testing set\n",
      "- Accuracy: 0.9948979591836735\n",
      "- MCC: 0.9691069179909034\n",
      "- F1 score: 0.9949636997656205\n"
     ]
    }
   ],
   "source": [
    "# DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier(random_state=1234)\n",
    "dt.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions on the training and testing sets\n",
    "y_train_pred = dt.predict(x_train)\n",
    "y_test_pred = dt.predict(x_test)\n",
    "\n",
    "# Training set performance\n",
    "dt_train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "dt_train_mcc = matthews_corrcoef(y_train, y_train_pred)\n",
    "dt_train_f1 = f1_score(y_train, y_train_pred, average='weighted')\n",
    "\n",
    "# Testing set performance\n",
    "dt_test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "dt_test_mcc = matthews_corrcoef(y_test, y_test_pred)\n",
    "dt_test_f1 = f1_score(y_test, y_test_pred, average='weighted')\n",
    "\n",
    "print('Model performance for Training set')\n",
    "print('- Accuracy: %s' % dt_train_accuracy)\n",
    "print('- MCC: %s' % dt_train_mcc)\n",
    "print('- F1 score: %s' % dt_train_f1)\n",
    "print('----------------------------------')\n",
    "print('Model performance for Testing set')\n",
    "print('- Accuracy: %s' % dt_test_accuracy)\n",
    "print('- MCC: %s' % dt_test_mcc)\n",
    "print('- F1 score: %s' % dt_test_f1)\n",
    "\n",
    "# Make predictions on the test dataset\n",
    "y_test_pred = dt.predict(x_test)\n",
    "\n",
    "# Save predictions to \"prediction.txt\"\n",
    "pd.DataFrame(y_test_pred, columns=[\"Predicted\"]).to_csv(\"prediction_DT.txt\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "52e6d14c-8f4c-44d6-9026-70451e970187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance for Training Set Using Stacking Model\n",
      "- Accuracy: 1.0\n",
      "- MCC: 1.0\n",
      "- F1 score: 1.0\n",
      "----------------------------------\n",
      "Model Performance for Testing Set Using Stacking Model\n",
      "- Accuracy: 0.9948979591836735\n",
      "- MCC: 0.9674439066004296\n",
      "- F1 score: 0.9948277614413706\n"
     ]
    }
   ],
   "source": [
    "#Stacking Model\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# Define base estimators\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "dt = DecisionTreeClassifier(random_state=1234)\n",
    "rf = RandomForestClassifier(random_state=1234)\n",
    "\n",
    "# Define the Stacking Classifier\n",
    "estimator_list = [('knn', knn),('dt', dt),('rf', rf)]\n",
    "\n",
    "stack_model = StackingClassifier(estimators=estimator_list, final_estimator=LogisticRegression())\n",
    "\n",
    "# Train the stacked model\n",
    "stack_model.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions on the training and Testing sets\n",
    "y_train_pred = stack_model.predict(x_train)\n",
    "y_test_pred = stack_model.predict(x_test)\n",
    "\n",
    "# Training set performance\n",
    "stack_model_train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "stack_model_train_mcc = matthews_corrcoef(y_train, y_train_pred)\n",
    "stack_model_train_f1 = f1_score(y_train, y_train_pred, average='weighted')\n",
    "\n",
    "# Testing set performance\n",
    "stack_model_test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "stack_model_test_mcc = matthews_corrcoef(y_test, y_test_pred)\n",
    "stack_model_test_f1 = f1_score(y_test, y_test_pred, average='weighted')\n",
    "\n",
    "print('Model Performance for Training Set Using Stacking Model')\n",
    "print('- Accuracy: %s' % stack_model_train_accuracy)\n",
    "print('- MCC: %s' % stack_model_train_mcc)\n",
    "print('- F1 score: %s' % stack_model_train_f1)\n",
    "print('----------------------------------')\n",
    "print('Model Performance for Testing Set Using Stacking Model')\n",
    "print('- Accuracy: %s' % stack_model_test_accuracy)\n",
    "print('- MCC: %s' % stack_model_test_mcc)\n",
    "print('- F1 score: %s' % stack_model_test_f1)\n",
    "\n",
    "# Make predictions on the test dataset\n",
    "y_test_pred = stack_model.predict(x_test)\n",
    "\n",
    "# Save predictions to \"prediction.txt\"\n",
    "pd.DataFrame(y_test_pred, columns=[\"Predicted\"]).to_csv(\"prediction_Stacking.txt\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea59e06",
   "metadata": {},
   "source": [
    "### Briefly describe your approach in the following cell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c942ae",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
