{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a39bba82",
   "metadata": {},
   "source": [
    "## <center> Assignment 2 </center>\n",
    "\n",
    "#### Name: Kaniz Fatema\n",
    "#### Student ID: 245832180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "08ed5695-63ad-489b-a9d0-27ad0b092849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all the essential libraries\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, matthews_corrcoef, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "aef60349-4cc2-4298-b623-29ee1dfd5c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "train_data = pd.read_csv(\"train.csv\")\n",
    "test_data = pd.read_csv(\"test_attribute.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "7814e003-e8f1-458a-9e17-410e2ad4703e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "Frequency for column 0:\u001b[0m\n",
      "0.51    32\n",
      "0.46    31\n",
      "0.45    29\n",
      "0.50    25\n",
      "0.47    23\n",
      "        ..\n",
      "0.83     1\n",
      "0.19     1\n",
      "0.22     1\n",
      "0.20     1\n",
      "0.24     1\n",
      "Length: 70, dtype: int64\n",
      "\u001b[1m\n",
      "Frequency for column 1:\u001b[0m\n",
      "0.46    32\n",
      "0.45    32\n",
      "0.48    28\n",
      "0.53    24\n",
      "0.51    23\n",
      "        ..\n",
      "0.21     1\n",
      "0.14     1\n",
      "0.18     1\n",
      "1.00     1\n",
      "0.80     1\n",
      "Length: 68, dtype: int64\n",
      "\u001b[1m\n",
      "Frequency for column 2:\u001b[0m\n",
      "0.54    42\n",
      "0.53    40\n",
      "0.51    39\n",
      "0.52    37\n",
      "0.50    35\n",
      "0.55    31\n",
      "0.56    29\n",
      "0.49    29\n",
      "0.48    26\n",
      "0.47    25\n",
      "0.45    24\n",
      "0.57    23\n",
      "0.46    22\n",
      "0.58    20\n",
      "0.43    15\n",
      "0.35    14\n",
      "0.38    14\n",
      "0.36    14\n",
      "0.34    14\n",
      "0.44    13\n",
      "0.42    13\n",
      "0.59    11\n",
      "0.60    10\n",
      "0.32     9\n",
      "0.41     9\n",
      "0.30     9\n",
      "0.61     8\n",
      "0.62     8\n",
      "0.33     8\n",
      "0.63     7\n",
      "0.64     7\n",
      "0.40     7\n",
      "0.39     7\n",
      "0.37     5\n",
      "0.29     3\n",
      "0.67     3\n",
      "0.71     3\n",
      "0.31     2\n",
      "0.75     2\n",
      "0.26     2\n",
      "0.65     2\n",
      "0.21     2\n",
      "0.69     2\n",
      "0.27     1\n",
      "0.24     1\n",
      "0.66     1\n",
      "1.00     1\n",
      "0.22     1\n",
      "0.72     1\n",
      "0.28     1\n",
      "dtype: int64\n",
      "\u001b[1m\n",
      "Frequency for column 3:\u001b[0m\n",
      "0.18    38\n",
      "0.17    32\n",
      "0.19    32\n",
      "0.16    30\n",
      "0.22    25\n",
      "        ..\n",
      "0.59     1\n",
      "0.57     1\n",
      "0.00     1\n",
      "0.80     1\n",
      "0.07     1\n",
      "Length: 65, dtype: int64\n",
      "\u001b[1m\n",
      "Frequency for column 4:\u001b[0m\n",
      "0.5    646\n",
      "1.0      6\n",
      "dtype: int64\n",
      "\u001b[1m\n",
      "Frequency for column 5:\u001b[0m\n",
      "0.00    644\n",
      "0.83      6\n",
      "0.50      2\n",
      "dtype: int64\n",
      "\u001b[1m\n",
      "Frequency for column 6:\u001b[0m\n",
      "0.51    67\n",
      "0.53    66\n",
      "0.52    62\n",
      "0.54    60\n",
      "0.50    55\n",
      "0.49    46\n",
      "0.48    46\n",
      "0.55    42\n",
      "0.46    25\n",
      "0.47    25\n",
      "0.56    21\n",
      "0.57    21\n",
      "0.44    21\n",
      "0.45    11\n",
      "0.59     9\n",
      "0.40     9\n",
      "0.43     9\n",
      "0.58     8\n",
      "0.60     6\n",
      "0.38     6\n",
      "0.41     6\n",
      "0.42     5\n",
      "0.36     5\n",
      "0.39     4\n",
      "0.34     3\n",
      "0.62     3\n",
      "0.30     3\n",
      "0.27     1\n",
      "0.32     1\n",
      "0.69     1\n",
      "0.37     1\n",
      "0.33     1\n",
      "0.13     1\n",
      "0.72     1\n",
      "0.26     1\n",
      "dtype: int64\n",
      "\u001b[1m\n",
      "Frequency for column 7:\u001b[0m\n",
      "0.22    383\n",
      "0.27     42\n",
      "0.25     33\n",
      "0.26     26\n",
      "0.31     25\n",
      "0.11     16\n",
      "0.28     14\n",
      "0.30     10\n",
      "0.29      6\n",
      "0.40      6\n",
      "0.36      6\n",
      "0.37      6\n",
      "0.42      6\n",
      "0.32      6\n",
      "0.16      5\n",
      "0.43      5\n",
      "0.33      5\n",
      "0.34      5\n",
      "0.38      4\n",
      "0.44      4\n",
      "0.39      4\n",
      "0.47      4\n",
      "0.35      3\n",
      "0.41      3\n",
      "0.14      2\n",
      "0.21      2\n",
      "0.54      2\n",
      "0.23      2\n",
      "0.63      1\n",
      "0.74      1\n",
      "0.58      1\n",
      "0.45      1\n",
      "0.68      1\n",
      "0.70      1\n",
      "0.48      1\n",
      "0.50      1\n",
      "0.01      1\n",
      "0.66      1\n",
      "0.57      1\n",
      "0.19      1\n",
      "0.49      1\n",
      "0.73      1\n",
      "0.64      1\n",
      "0.18      1\n",
      "0.65      1\n",
      "dtype: int64\n",
      "\u001b[1m\n",
      "Frequency for column 8:\u001b[0m\n",
      "0    588\n",
      "1     64\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Understanding the given training dataset\n",
    "train_data_columns = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\"]\n",
    "\n",
    "# Calculate and print the frequency of each value in the specified columns\n",
    "for column in train_data_columns:\n",
    "    if column in train_data.columns:  # Check if the column exists in train_data\n",
    "        print(f\"\\033[1m\\nFrequency for column {column}:\\033[0m\")\n",
    "        frequency = train_data[column].value_counts()\n",
    "        frequency.index.name = None  # Remove index name to avoid unexpected output\n",
    "        frequency.name = None        # Remove series name to avoid 'Name: count' in output\n",
    "        print(frequency)\n",
    "    else:\n",
    "        print(f\"\\033[1;31mColumn '{column}' not found in train_data.\\033[0m\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "617eba49-8330-4e3d-82b6-6f2daa056514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mNumber of missing values in each column:\u001b[0m\n",
      "Unnamed: 0    0\n",
      "0             0\n",
      "1             0\n",
      "2             0\n",
      "3             0\n",
      "4             0\n",
      "5             0\n",
      "6             0\n",
      "7             0\n",
      "8             0\n",
      "dtype: int64\n",
      "\u001b[1m\n",
      "Total number of missing values in the crx dataset: 0\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Identify and report the number of missing values in the training dataset.\n",
    "missing_values_count = train_data.isna().sum()\n",
    "# Report the number of missing values in each column\n",
    "print(\"\\033[1mNumber of missing values in each column:\\033[0m\")\n",
    "print(missing_values_count)\n",
    "# Report the total number of missing values in the dataset\n",
    "total_missing_values = missing_values_count.sum()\n",
    "# Print the total number of missing values in bold\n",
    "print(f\"\\033[1m\\nTotal number of missing values in the crx dataset: {total_missing_values}\\033[0m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "7c4abca2-d1fa-48a1-8eb0-cd380c574acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and labels\n",
    "x = train_data.iloc[:, :-1]\n",
    "y = train_data.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "e154b350-98af-4774-8424-9302796051c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mIllustration of the X values:\u001b[0m\n",
      "\u001b[1m---------------------------------------\u001b[0m\n",
      "   Unnamed: 0     0     1     2     3    4    5     6     7\n",
      "0           0  0.81  0.85  0.47  0.37  0.5  0.0  0.56  0.22\n",
      "1           1  0.70  0.58  0.53  0.39  0.5  0.0  0.59  0.22\n",
      "2           2  0.72  0.73  0.41  0.28  0.5  0.0  0.44  0.22\n",
      "3           3  0.78  0.69  0.44  0.26  0.5  0.0  0.54  0.22\n",
      "4           4  0.74  0.82  0.46  0.24  0.5  0.0  0.48  0.22\n",
      "\u001b[1mIllustration of the Y values:\u001b[0m\n",
      "\u001b[1m---------------------------------------\u001b[0m\n",
      "0    1\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "4    1\n",
      "Name: 8, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Print the values of x and y\n",
    "print(\"\\033[1mIllustration of the X values:\\033[0m\")\n",
    "print(\"\\033[1m---------------------------------------\\033[0m\")\n",
    "print(x.head())\n",
    "\n",
    "print(\"\\033[1mIllustration of the Y values:\\033[0m\")\n",
    "print(\"\\033[1m---------------------------------------\\033[0m\")\n",
    "print(y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "372ba64c-5829-475c-879c-cbc48a5c9a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mTraining set shape: (521, 9), Testing set shape: (131, 9)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Split training data for testing\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=1234)\n",
    "print(f\"\\033[1mTraining set shape: {x_train.shape}, Testing set shape: {x_test.shape}\\033[0m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "ab8d7879-6383-4e3a-a739-2bb86f172015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Processing: Scale the data\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "b956328f-f997-4b69-93b8-4d4f6991e189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCounts of labels in the Training set:\u001b[0m\n",
      "8\n",
      "0    465\n",
      "1     56\n",
      "Name: count, dtype: int64\n",
      "\u001b[1mCounts of labels in the Testing set:\u001b[0m\n",
      "8\n",
      "0    123\n",
      "1      8\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count number of 0s and 1s in training and testing labels\n",
    "train_label_counts = y_train.value_counts()\n",
    "test_label_counts = y_test.value_counts()\n",
    "print(\"\\033[1mCounts of labels in the Training set:\\033[0m\")\n",
    "print(train_label_counts)\n",
    "print(\"\\033[1mCounts of labels in the Testing set:\\033[0m\")\n",
    "print(test_label_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538d9c03-dc61-475b-826e-f86f8ea3df82",
   "metadata": {},
   "source": [
    "### Classifier-1: KNeighborsClassifier (KNN) ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "54209a35-f995-4a69-9a61-f5aeb6f41c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mModel performance for Testing set using KNN\u001b[0m\n",
      "- Accuracy: 0.9694656488549618\n",
      "- MCC: 0.9284521016642407\n",
      "- F1 score: 0.9710368609129716\n"
     ]
    }
   ],
   "source": [
    "# KNeighborsClassifier (KNN)\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions on the training and testing sets\n",
    "y_train_pred = knn.predict(x_train)\n",
    "y_test_pred = knn.predict(x_test)\n",
    "\n",
    "# Testing set performance\n",
    "knn_test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "knn_test_mcc = matthews_corrcoef(y_train, y_train_pred)\n",
    "knn_test_f1 = f1_score(y_test, y_test_pred, average='weighted')\n",
    "\n",
    "print('\\033[1mModel performance for Testing set using KNN\\033[0m')\n",
    "print('- Accuracy: %s' % knn_test_accuracy)\n",
    "print('- MCC: %s' % knn_test_mcc)\n",
    "print('- F1 score: %s' % knn_test_f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a595240-06ab-405d-815f-3bee6892f757",
   "metadata": {},
   "source": [
    "### Generating the prediction.txt file for the KNeighborsClassifier (KNN) classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "3e40dc08-96c1-459b-823f-d14019435b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mPredictions saved to prediction_KNN.txt\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Scale the test dataset and make predictions for the KNN model\n",
    "x_test_scaled = scaler.transform(test_data)\n",
    "y_test_pred = knn.predict(x_test_scaled)\n",
    "# Save predictions to \"prediction_KNN.txt\"\n",
    "pd.DataFrame(y_test_pred, columns=[\"Predicted\"]).to_csv(\"prediction_KNN.txt\", header=False, index=False)\n",
    "print(\"\\033[1mPredictions saved to prediction_KNN.txt\\033[0m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb2e512-dc11-4657-9372-21ba328309b0",
   "metadata": {},
   "source": [
    "### Classifier-2: Logistic Regression Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "42eef4fb-e1b0-4178-b044-54cc8ddb407c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mModel performance for Testing set using Logistic Regression\u001b[0m\n",
      "- Accuracy: 0.9847328244274809\n",
      "- MCC: 0.866869918699187\n",
      "- F1 score: 0.9847328244274809\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression Classifier\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "log_reg = LogisticRegression(random_state=42)  # Instantiate Logistic Regression\n",
    "log_reg.fit(x_train, y_train)  # Fit the model\n",
    "\n",
    "# Make predictions on the training and testing sets\n",
    "y_train_pred = log_reg.predict(x_train)\n",
    "y_test_pred = log_reg.predict(x_test)\n",
    "\n",
    "# Testing set performance\n",
    "log_reg_train_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "log_reg_train_mcc = matthews_corrcoef(y_test, y_test_pred)\n",
    "log_reg_train_f1 = f1_score(y_test, y_test_pred, average='weighted')\n",
    "\n",
    "print('\\033[1mModel performance for Testing set using Logistic Regression\\033[0m')\n",
    "print('- Accuracy: %s' % log_reg_test_accuracy)\n",
    "print('- MCC: %s' % log_reg_test_mcc)\n",
    "print('- F1 score: %s' % log_reg_test_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74fb8a09-97fd-48dc-94cb-98f77f9dd7ff",
   "metadata": {},
   "source": [
    "### Generating the prediction.txt file for the Logistic Regression (LR) classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "9a927719-499c-4633-8a0e-4754b43495ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mPredictions saved to prediction_LR.txt\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Scale the test dataset and make predictions for the LR model\n",
    "x_test_scaled = scaler.transform(test_data)\n",
    "y_test_pred = log_reg.predict(x_test_scaled)\n",
    "# Save predictions to \"prediction_LR.txt\"\n",
    "pd.DataFrame(y_test_pred, columns=[\"Predicted\"]).to_csv(\"prediction_LR.txt\", header=False, index=False)\n",
    "print(\"\\033[1mPredictions saved to prediction_LR.txt\\033[0m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b24025b-199c-41ae-b7c1-60333774c7b9",
   "metadata": {},
   "source": [
    "### Briefly describe your approach in the following cell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53b86a7-a7eb-49fc-b08f-61c6bbe21a23",
   "metadata": {},
   "source": [
    "# Here's a brief description of the approach in the provided code cell: ( All the process is occured in a sequential order)\n",
    "1. Library Importation: Import pandas, seaborn, matplotlib.pyplot, and necessary sklearn classes for data processing, visualization, and assessment.\n",
    "2. Data Loading: Training and test datasets are loaded into DataFrames with pandas. This allows for the following analysis and processing of the datasets.\n",
    "3. Data understanding (Finding frequencies and missing value analysis):\n",
    "   Finding Frequency: The value_counts() function is used to compute and report the frequency of values in provided columns. Column existence is checked to prevent problems. The frequency Series index and name are reset to improve output quality.\n",
    "\n",
    "   Missing Value Analysis: The amount of missing values in each column is calculated and reported. This contains both the number of missing values per column and the overall number of missing values in the dataset, which are bolded for emphasis.\n",
    "\n",
    "4. Modeling involves separating characteristics (X) and labels (y). The characteristics include all columns except the last one, with the last column considered to represent the label of the dataset.\n",
    "\n",
    "5. Data Inspection: Print the first rows of the feature set (X) and label set (y) to get an overview of the data structure and content.\n",
    "\n",
    "6. Data Splitting: To guarantee repeatability, the dataset is split into training and testing subsets using sklearn's train_test_split function. The test size and random state are supplied by examining with several parameters.\n",
    "\n",
    "7. Data Scaling: StandardScaler is used to normalize feature values, which is important for machine learning methods.\n",
    "\n",
    "8. Label Count Analysis: We compute and report the counts of labels (0s and 1s) in both training and testing sets to get insight into class distribution.\n",
    "\n",
    "# Classifier: After using the methods described above, it is critical to choose the best classifier to classify (Binary) the data. In this regard, numerous models were used. Since KNN and LR outperformed the others, these are finalized based on their performance. Furthermore, when compared to the KNN model (F1 score: 0.9710368609129716), the LR model outperformed (using testing data) it in terms of F1-score (F1 score: 0.9847328244274809).\n",
    "\n",
    "\n",
    "10. # For the Optimal Model: Logistic Regression (LR) classifier.\n",
    "\n",
    "Initiating the model: Sklearn.linear_model's LogisticRegression() instantiates a logistic regression model.\n",
    "Model training: Fitting the model to x_train and y_train data. Training entails learning the feature-target variable connection.Training and testing datasets are predicted by the trained model. Result files are y_train_pred and y_test_pred.\n",
    "Evaluate Performance: Calculate models' Accuracy,MCC, and F1 score on testing data set.\n",
    "\n",
    "11. # Generating the prediction.txt file for the Logistic Regression (LR) classifier.\n",
    "The scaler.transform method is used to standardize the test dataset, ensuring a mean of 0 and standard deviation of 1. The predicted labels are then generated using the trained logistic regression model ( utilizing the given testing dataset). The predictions are saved to a text file named \"prediction_LR.txt\" using a Pandas DataFrame. A confirmation message is then printed to the console.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
